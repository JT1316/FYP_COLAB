{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FYP_CLASSIFICATION_CIFAR_FOURIER_Genetic.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNkHwvAR2vBe3b7d6K1d36q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zBdLmZVtbhUV","colab_type":"text"},"source":["Credit to https://github.com/harvitronix/neural-network-genetic-algorithm "]},{"cell_type":"code","metadata":{"id":"OXrfo9lTqqfT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1589977073028,"user_tz":-60,"elapsed":6599,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"61ba8749-130b-4088-8f7a-eef9419ed384"},"source":["from keras.datasets import mnist,cifar10\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras import regularizers\n","from keras.utils import np_utils\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"J002Sq7XqExW","colab_type":"code","colab":{}},"source":["def compute_mag_phase(toBeTransfromed):\n","    dft = np.fft.fft2(toBeTransfromed)\n","    dft_shift = np.fft.fftshift(dft)\n","    mag = np.abs(dft_shift)\n","    ang = np.angle(dft_shift)\n","    return mag, ang\n","\n","def reconstruct(mag,ang):\n","    combined = np.multiply(mag, np.exp(1j*ang))\n","    fftx = np.fft.ifftshift(combined)\n","    ffty = np.fft.ifft2(fftx)\n","    imgCombined = np.abs(ffty)\n","    return imgCombined\n","\n","def pre_process_mag(dataset):\n","    mag = np.zeros(dataset.shape)\n","    phase = np.zeros(dataset.shape)\n","    x= 0\n","    for i in range(0,dataset.shape[0]):\n","      mag[i,:,:],phase[i,:,:] = compute_mag_phase(dataset[i])\n","    return mag,phase\n","\n","\n","def reconstructAll(mag, ang):\n","    recon = np.zeros(mag.shape)\n","    for i in range(0,recon.shape[0]):\n","      recon[i,:,:] = reconstruct(mag[i,:,:],ang[i,:,:])\n","    return recon"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jy3RJzRqlIV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1589977078411,"user_tz":-60,"elapsed":11960,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"57fcaf87-1a2e-4305-ebfc-82c6a44f0e67"},"source":["# the data, shuffled and split between train and val sets\n","# Here we are using the official test set as our validation set, in further\n","# tutorials, test and validation splits will be explained properly.\n","(x1_train, y1_train), (x1_test, y1_test) = cifar10.load_data()\n","\n","print('Image shape: {0}'.format(x1_train.shape[1:]))\n","print('Total number of training samples: {0}'.format(x1_train.shape[0]))\n","print('Total number of test samples: {0}'.format(x1_test.shape[0]))\n","\n","x1_train = x1_train.astype('float32')\n","x1_test = x1_test.astype('float32')\n","\n","# Normalize the image\n","x1_train /= 255\n","x1_test /= 255\n","\n","print(x1_train.shape)\n","\n","y1_train_class = np_utils.to_categorical(y1_train, 10)\n","y1_test_class = np_utils.to_categorical(y1_test, 10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Image shape: (32, 32, 3)\n","Total number of training samples: 50000\n","Total number of test samples: 10000\n","(50000, 32, 32, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cw8BvvmbqIyn","colab_type":"code","colab":{}},"source":["import random\n","import numpy as np\n","np.random.seed(100)\n","noise_mag = np.random.uniform(size = (32,32,3),low = 0.0, high = 7.0)\n","\n","const_mag = np.full((32, 32, 3), 1.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElPecB-qqObu","colab_type":"code","colab":{}},"source":["def reconstructPhase(mag, ang):\n","    recon = np.zeros(ang.shape)\n","    for i in range(0,recon.shape[0]):\n","      recon[i,:,:] = reconstruct(mag,ang[i,:,:])\n","    return recon"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa1sfMhnqSVf","colab_type":"code","colab":{}},"source":["dc, x_train_phase = pre_process_mag(x1_train)\n","del dc\n","dc, x_test_phase = pre_process_mag(x1_test)\n","del dc\n","x_train_recon_phase = reconstructPhase(const_mag,  x_train_phase)\n","del x_train_phase\n","x_test_recon_phase = reconstructPhase(const_mag,  x_test_phase)\n","del x_test_phase"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACAy7iRCqYTv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1589977136962,"user_tz":-60,"elapsed":1803,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"63f5745a-8390-4ed2-ae20-ea7c0569e047"},"source":["import matplotlib.pyplot as plt\n","\n","plt.subplot(221)\n","plt.imshow(x1_train[2])\n","plt.subplot(222)\n","plt.imshow(x_train_recon_phase[2])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f5b04486c50>"]},"metadata":{"tags":[]},"execution_count":7},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"v8vnvWLOR_Au","colab_type":"code","colab":{}},"source":["del x1_train\n","del x1_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMum-SS-oXaM","colab_type":"code","colab":{}},"source":["early_stopper = EarlyStopping(monitor='val_accuracy',patience=1)\n","\n","def get_cifar_const_mag():\n","    # Set defaults.\n","    nb_classes = 10\n","    batch_size = 32\n","    input_shape = (32, 32, 3)\n","\n","    # Get the data.\n","    x_train = x_train_recon_phase\n","    y_train = y1_train_class\n","    x_test = x_test_recon_phase\n","    y_test = y1_test_class\n","\n","    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n","\n","\n","def get_cifar10():\n","    # Set defaults.\n","    nb_classes = 10\n","    batch_size = 32\n","    input_shape = (32, 32, 3)\n","\n","    # Get the data.\n","    x_train = x1_train\n","    y_train = y1_train_class\n","    x_test = x1_test\n","    y_test = y1_test_class\n","\n","    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n","\n","def compile_model(network, nb_classes, input_shape):\n","    \"\"\"Compile a sequential model.\n","    Args:\n","        network (dict): the parameters of the network\n","    Returns:\n","        a compiled network.\n","    \"\"\"\n","    # Get our network parameters.\n","        #'VGG_layers': range(1,5),\n","        #VGG_sublayers': range(1,4),\n","\n","    VGG_layers = network['VGG_layers']\n","    VGG_sublayers = network['VGG_sublayers']\n","    pool_num =network['pool_num']\n","\n","    nb_layers = network['nb_layers']\n","    nb_neurons1 = network['nb_neurons1']\n","    nb_neurons2 = network['nb_neurons2']\n","    nb_neurons3 = network['nb_neurons3']\n","    nb_neurons4 = network['nb_neurons4']\n","    activation = network['activation']\n","    optimizer = network['optimizer']\n","    dropout1 = network['dropout1']\n","    dropout2 = network['dropout2']\n","\n","    if network['optimizer'] == 'rmsprop':\n","      optimizer =  RMSprop(lr=0.0001, decay=1e-6)\n","\n","    model = Sequential()\n","\n","    if VGG_layers == 0:                        #no conv layers\n","      for i in range(nb_layers):\n","\n","          # Need input shape for first layer.\n","          if i == 0:\n","              model.add(Flatten(input_shape=(32,32,3)))\n","              model.add(Dense(nb_neurons1, activation=activation))\n","          elif i == 1:\n","              model.add(Dense(nb_neurons2, activation=activation))\n","          elif i == 2:\n","              model.add(Dense(nb_neurons3, activation=activation))\n","          elif i == 3:\n","              model.add(Dense(nb_neurons4, activation=activation))\n","\n","          model.add(Dropout(dropout2))  # hard-coded dropout\n","\n","    else:\n","      for i in range(VGG_layers):\n","          if i == 0:\n","              model.add(Conv2D(32, (3,3), padding='same', input_shape=(32, 32, 3)))\n","              model.add(Activation(activation))\n","              if (VGG_sublayers > 1) :\n","                for x in range(1, VGG_sublayers):\n","                  model.add(Conv2D(32, (3,3), padding='same'))\n","                  model.add(Activation(activation))\n","              model.add(MaxPooling2D(pool_size=(pool_num,pool_num)))\n","              model.add(Dropout(dropout1))\n","          else:\n","              for x in range(0, VGG_sublayers):\n","                model.add(Conv2D((32*(2**i)), (3,3), padding='same'))\n","                model.add(Activation(activation))\n","              model.add(MaxPooling2D(pool_size=(pool_num,pool_num)))\n","              model.add(Dropout(dropout1))\n","\n","      for i in range(nb_layers):\n","          # Need input shape for first layer.\n","          if i == 0:\n","              model.add(Flatten())\n","              model.add(Dense(nb_neurons1, activation=activation))\n","          elif i == 1:\n","              model.add(Dense(nb_neurons2, activation=activation))\n","          elif i == 2:\n","              model.add(Dense(nb_neurons3, activation=activation))\n","          elif i == 3:\n","              model.add(Dense(nb_neurons4, activation=activation))\n","\n","          model.add(Dropout(dropout2))  # hard-coded dropout\n","\n","\n","\n","\n","    # Output layer.\n","    #model.add(Flatten())\n","    model.add(Dense(nb_classes, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n","                  metrics=['accuracy'])\n","    print('compiled model')\n","    return model\n","\n","def train_and_score(network, dataset):\n","    \"\"\"Train the model, return test loss.\n","    Args:\n","        network (dict): the parameters of the network\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","    logging.info(\"***train_and_score***\")\n","    if dataset == 'cifar10':\n","        nb_classes, batch_size, input_shape, x_train, \\\n","            x_test, y_train, y_test = get_cifar10()\n","    elif dataset == 'const_mag':\n","        logging.info(\"***const_mag***\")\n","        nb_classes, batch_size, input_shape, x_train, \\\n","            x_test, y_train, y_test = get_cifar_const_mag()\n","\n","    model = compile_model(network, nb_classes, input_shape)\n","    logging.info(\"***compiled_model***\")\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=50,  # using early stopping, so no real limit\n","              verbose=1,\n","              #validation_data=(x_test, y_test),\n","              validation_split=0.2,\n","              callbacks=[early_stopper])\n","              #validation_split=0.2, epochs=100, batch_size=2000,\n","              #validation_data=(x_test, y_test))\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    logging.info(\"***trainedd***\")\n","    print(score[1])\n","    return score[1]  # 1 is accuracy. 0 is loss."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcRdFk5HsQz9","colab_type":"code","colab":{}},"source":["import random\n","import logging\n","#from train import train_and_score\n","\n","class Network():\n","    \"\"\"Represent a network and let us operate on it.\n","    Currently only works for an MLP.\n","    \"\"\"\n","\n","    def __init__(self, nn_param_choices=None):\n","        \"\"\"Initialize our network.\n","        Args:\n","            nn_param_choices (dict): Parameters for the network, includes:\n","                nb_neurons (list): [64, 128, 256]\n","                nb_layers (list): [1, 2, 3, 4]\n","                activation (list): ['relu', 'elu']\n","                optimizer (list): ['rmsprop', 'adam']\n","        \"\"\"\n","        self.accuracy = 0.\n","        self.nn_param_choices = nn_param_choices\n","        self.network = {}  # (dic): represents MLP network parameters\n","\n","    def create_random(self):\n","        i = True \n","        \"\"\"Create a random network.\"\"\"\n","        for key in self.nn_param_choices:\n","            if key == 'nb_neurons2':\n","              while (True):\n","                logging.info(\"stuck 1\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons1']:\n","                  break\n","            elif key == 'nb_neurons3':\n","              while (True):\n","                logging.info(\"stuck 2\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons2']:\n","                  break\n","            elif key == 'nb_neurons4':\n","              while (True):\n","                logging.info(\"stuck 3\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons3']:\n","                  break\n","            else:\n","              self.network[key] = random.choice(self.nn_param_choices[key])\n","\n","\n","\n","    def create_set(self, network):\n","        \"\"\"Set network properties.\n","        Args:\n","            network (dict): The network parameters\n","        \"\"\"\n","        self.network = network\n","\n","    def train(self, dataset):\n","        \"\"\"Train the network and record the accuracy.\n","        Args:\n","            dataset (str): Name of dataset to use.\n","        \"\"\"\n","        logging.info(\"***train***\")\n","        if self.accuracy == 0.:\n","            self.accuracy = train_and_score(self.network, dataset)\n","\n","    def print_network(self):\n","        \"\"\"Print out a network.\"\"\"\n","        logging.info(self.network)\n","        logging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LK2mY_xsZ5D","colab_type":"code","colab":{}},"source":["from functools import reduce\n","from operator import add\n","import random\n","\n","\n","class Optimizer():\n","    \"\"\"Class that implements genetic algorithm for MLP optimization.\"\"\"\n","\n","    def __init__(self, nn_param_choices, retain=0.4,\n","                 random_select=0.1, mutate_chance=0.6):\n","        \"\"\"Create an optimizer.\n","        Args:\n","            nn_param_choices (dict): Possible network paremters\n","            retain (float): Percentage of population to retain after\n","                each generation\n","            random_select (float): Probability of a rejected network\n","                remaining in the population\n","            mutate_chance (float): Probability a network will be\n","                randomly mutated\n","        \"\"\"\n","        self.mutate_chance = mutate_chance\n","        self.random_select = random_select\n","        self.retain = retain\n","        self.nn_param_choices = nn_param_choices\n","\n","    def create_population(self, count):\n","        \"\"\"Create a population of random networks.\n","        Args:\n","            count (int): Number of networks to generate, aka the\n","                size of the population\n","        Returns:\n","            (list): Population of network objects\n","        \"\"\"\n","        pop = []\n","        for _ in range(0, count):\n","            # Create a random network.\n","            network = Network(self.nn_param_choices)\n","            logging.info(\"count\")\n","            network.create_random()\n","\n","            # Add the network to our population.\n","            pop.append(network)\n","\n","        return pop\n","\n","    @staticmethod\n","    def fitness(network):\n","        \"\"\"Return the accuracy, which is our fitness function.\"\"\"\n","        return network.accuracy\n","\n","    def grade(self, pop):\n","        \"\"\"Find average fitness for a population.\n","        Args:\n","            pop (list): The population of networks\n","        Returns:\n","            (float): The average accuracy of the population\n","        \"\"\"\n","        summed = reduce(add, (self.fitness(network) for network in pop))\n","        return summed / float((len(pop)))\n","\n","    def breed(self, mother, father):\n","        \"\"\"Make two children as parts of their parents.\n","        Args:\n","            mother (dict): Network parameters\n","            father (dict): Network parameters\n","        Returns:\n","            (list): Two network objects\n","        \"\"\"\n","        children = []\n","        for _ in range(2):\n","\n","            child = {}\n","\n","            #  need to do if they have equal layers\n","            # Loop through the parameters and pick params for the kid.\n","            for param in self.nn_param_choices:\n","                  if (param == 'nb_neurons2') :\n","                    while (True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons1']:\n","                            break\n","                            logging.info(\"***broke1***\")\n","                  elif param == 'nb_neurons3':\n","                    while ( True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons2']:\n","                            break\n","                            logging.info(\"***broke2***\")\n","                  elif param == 'nb_neurons4':\n","                    while (True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons3']:\n","                            break\n","                            logging.info(\"***broke3***\")\n","                  else:\n","                    child[param] = random.choice([mother.network[param], father.network[param]])\n","\n","            # Now create a network object.\n","            network = Network(self.nn_param_choices)\n","            network.create_set(child)\n","\n","            # Randomly mutate some of the children.\n","            if self.mutate_chance > random.random():\n","                network = self.mutate(network)\n","\n","            children.append(network)\n","\n","        return children\n","\n","    def mutate(self, network):\n","        \"\"\"Randomly mutate one part of the network.\n","        Args:\n","            network (dict): The network parameters to mutate\n","        Returns:\n","            (Network): A randomly mutated network object\n","        \"\"\"\n","        # Choose a random key.\n","\n"," \n","        mutation = random.choice(list(self.nn_param_choices.keys()))\n","        \n","        #mutate param within condition\n","        if mutation == 'nb_neurons1':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons2']):\n","                    break\n","        elif mutation == 'nb_neurons2':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons3']) and (network.network[mutation] < network.network['nb_neurons1']) :\n","                    break\n","        elif mutation == 'nb_neurons3':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons4'])  and (network.network[mutation] < network.network['nb_neurons2']):\n","                    break\n","        elif mutation == 'nb_neurons4':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] < network.network['nb_neurons3']):\n","                    break\n","        else:\n","          # Mutate one of the params.\n","          network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","        return network\n","\n","    def evolve(self, pop):\n","        \"\"\"Evolve a population of networks.\n","        Args:\n","            pop (list): A list of network parameters\n","        Returns:\n","            (list): The evolved population of networks\n","        \"\"\"\n","        # Get scores for each network.\n","        graded = [(self.fitness(network), network) for network in pop]\n","\n","        # Sort on the scores.\n","        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n","\n","        # Get the number we want to keep for the next gen.\n","        retain_length = int(len(graded)*self.retain)\n","\n","        # The parents are every network we want to keep.\n","        parents = graded[:retain_length]\n","\n","        # For those we aren't keeping, randomly keep some anyway.\n","        for individual in graded[retain_length:]:\n","            if self.random_select > random.random():\n","                parents.append(individual)\n","\n","        # Now find out how many spots we have left to fill.\n","        parents_length = len(parents)\n","        desired_length = len(pop) - parents_length\n","        children = []\n","\n","        # Add children, which are bred from two remaining networks.\n","        while len(children) < desired_length:\n","\n","            # Get a random mom and dad.\n","            print(parents_length-1)\n","            male = random.randint(0, parents_length-1)\n","\n","            female = random.randint(0, parents_length-1)\n","\n","            # Assuming they aren't the same network...\n","            if male != female:\n","                male = parents[male]\n","                female = parents[female]\n","\n","                # Breed them.\n","                babies = self.breed(male, female)\n","\n","                # Add the children one at a time.\n","                for baby in babies:\n","                    # Don't grow larger than desired length.\n","                    if len(children) < desired_length:\n","                        children.append(baby)\n","\n","        parents.extend(children)\n","\n","        return parents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rT52dn8-sgBx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"status":"error","timestamp":1589985261665,"user_tz":-60,"elapsed":12373,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"5f5399f5-7e51-4201-a3e7-c15874feb8e4"},"source":["import logging\n","from tqdm import tqdm\n","\n","# Setup logging.\n","logging.basicConfig(\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    datefmt='%m/%d/%Y %I:%M:%S %p',\n","    level=logging.DEBUG,\n","    filename='log.txt'\n",")\n","\n","def train_networks(networks, dataset):\n","    \"\"\"Train each network.\n","    Args:\n","        networks (list): Current population of networks\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","\n","    pbar = tqdm(total=len(networks))\n","    logging.info(\"***a***\")\n","    for network in networks:\n","        network.train(dataset)\n","        pbar.update(1)\n","        logging.info(\"***b***\")\n","    pbar.close()\n","\n","def get_average_accuracy(networks):\n","    \"\"\"Get the average accuracy for a group of networks.\n","    Args:\n","        networks (list): List of networks\n","    Returns:\n","        float: The average accuracy of a population of networks.\n","    \"\"\"\n","    total_accuracy = 0\n","    for network in networks:\n","        total_accuracy += network.accuracy\n","\n","    return total_accuracy / len(networks)\n","\n","def generate(generations, population, nn_param_choices, dataset):\n","    \"\"\"Generate a network with the genetic algorithm.\n","    Args:\n","        generations (int): Number of times to evole the population\n","        population (int): Number of networks in each generation\n","        nn_param_choices (dict): Parameter choices for networks\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","    optimizer = Optimizer(nn_param_choices)\n","    logging.info(\"***Optimizer***\")\n","    networks = optimizer.create_population(population)\n","\n","    # Evolve the generation.\n","    for i in range(generations):\n","        logging.info(\"***Doing generation %d of %d***\" %\n","                     (i + 1, generations))\n","\n","        # Train and get accuracy for networks.\n","        train_networks(networks, dataset)\n","        logging.info(\"***Trained networks***\")\n","        # Get the average accuracy for this generation.\n","        average_accuracy = get_average_accuracy(networks)\n","\n","        # Print out the average accuracy each generation.\n","        logging.info(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n","        logging.info('-'*80)\n","        networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n","        print_networks(networks[:5])\n","        # Evolve, except on the last iteration.\n","        if i != generations - 1:\n","            # Do the evolution.\n","            networks = optimizer.evolve(networks)\n","\n","    # Sort our final population.\n","    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n","\n","    # Print out the top 5 networks.\n","    print_networks(networks[:5])\n","\n","def print_networks(networks):\n","    \"\"\"Print a list of networks.\n","    Args:\n","        networks (list): The population of networks\n","    \"\"\"\n","    logging.info('-'*80)\n","    for network in networks:\n","        network.print_network()\n","\n","def main():\n","    \"\"\"Evolve a network.\"\"\"\n","    generations = 10 # Number of times to evole the population.\n","    population = 15 # Number of networks in each generation.\n","    dataset = 'const_mag'\n","    print(2)\n","\n","    nn_param_choices = {\n","        #'nb_neurons': [10, 60, 110, 160, 210, 260,310,360,410,460,510],\n","        'VGG_layers': range(1,4),  # can start at 0\n","        'VGG_sublayers': range(1,4),\n","        'pool_num' : [2],\n","        'nb_neurons1': range(14,780),   # this can be too high and cause errors, possibly reduce\n","        'nb_neurons2':  range(13,779),  # being too large can mean too many trainable paramters\n","        'nb_neurons3': range(12,778),\n","        'nb_neurons4': range(11,777),\n","        'nb_layers': [1, 2, 3, 4],\n","        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n","        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n","                      'adadelta', 'adamax', 'nadam'],\n","        'dropout1': [0, 0.05, 0.1,0.15,0.2,0.25,0.3],\n","        'dropout2': [0, 0.05, 0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6]\n","    }\n","    print(3)\n","    logging.info(\"***Evolving %d generations with population %d***\" %\n","                 (generations, population))\n","    print(4)\n","    generate(generations, population, nn_param_choices, dataset)\n","    print('done')\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n","  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["2\n","3\n","4\n","compiled model\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[0;31m# without introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4523\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'sparse_read'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f8b7ad8db911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-f8b7ad8db911>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m                  (generations, population))\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_param_choices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-f8b7ad8db911>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(generations, population, nn_param_choices, dataset)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Train and get accuracy for networks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtrain_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***Trained networks***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the average accuracy for this generation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-f8b7ad8db911>\u001b[0m in \u001b[0;36mtrain_networks\u001b[0;34m(networks, dataset)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***a***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***b***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-0b528ea07c96>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***train***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-372352b46c40>\u001b[0m in \u001b[0;36mtrain_and_score\u001b[0;34m(network, dataset)\u001b[0m\n\u001b[1;32m    140\u001b[0m               \u001b[0;31m#validation_data=(x_test, y_test),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m               callbacks=[early_stopper])\n\u001b[0m\u001b[1;32m    143\u001b[0m               \u001b[0;31m#validation_split=0.2, epochs=100, batch_size=2000,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m               \u001b[0;31m#validation_data=(x_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    795\u001b[0m           data_adapter.train_validation_split((x, y, sample_weight),\n\u001b[1;32m    796\u001b[0m                                               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                                               shuffle=False))\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   train_arrays = nest.map_structure(\n\u001b[0;32m-> 1338\u001b[0;31m       functools.partial(_split, indices=train_indices), arrays)\n\u001b[0m\u001b[1;32m   1339\u001b[0m   val_arrays = nest.map_structure(\n\u001b[1;32m   1340\u001b[0m       functools.partial(_split, indices=val_indices), arrays)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_split\u001b[0;34m(t, indices)\u001b[0m\n\u001b[1;32m   1333\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   train_arrays = nest.map_structure(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   4539\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4540\u001b[0m       \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m       batch_dims=batch_dims)\n\u001b[0m\u001b[1;32m   4542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   3744\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3745\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GatherV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3746\u001b[0;31m         tld.op_callbacks, params, indices, axis, \"batch_dims\", batch_dims)\n\u001b[0m\u001b[1;32m   3747\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, message, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Exception class to handle not ok Status.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ksP2pw_dFC7r","colab_type":"text"},"source":["05/20/2020 11:03:17 AM - INFO - {'VGG_layers': 3, 'VGG_sublayers': 3, 'pool_num': 2, 'nb_neurons1': 501, 'nb_neurons2': 327, 'nb_neurons3': 285, 'nb_neurons4': 22, 'nb_layers': 3, 'activation': 'tanh', 'optimizer': 'rmsprop', 'dropout1': 0.05, 'dropout2': 0.15}\n","05/20/2020 11:03:17 AM - INFO - Network accuracy: 48.48%"]},{"cell_type":"code","metadata":{"id":"luglwn9tXztb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1589985977524,"user_tz":-60,"elapsed":1607,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"7d991006-2706-494e-9fc8-97a37b05c94e"},"source":["activation = 'tanh'\n","pool_num = 2\n","\n","\n","model = Sequential()\n","#####################################################################\n","model.add(Conv2D(32, (3,3), padding='same', input_shape=(32, 32, 3)))\n","model.add(Activation(activation))\n","model.add(Conv2D((32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(Conv2D((32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(pool_num,pool_num)))\n","model.add(Dropout(0.05))\n","\n","model.add(Conv2D(((2)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(Conv2D(((2)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(Conv2D(((2)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(pool_num,pool_num)))\n","model.add(Dropout(0.05))\n","\n","model.add(Conv2D(((4)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(Conv2D(((4)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(Conv2D(((4)*32), (3,3), padding='same'))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(pool_num,pool_num)))\n","model.add(Dropout(0.05))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(501, activation=activation))\n","model.add(Dense(327, activation=activation))\n","model.add(Dense(285, activation=activation))\n","model.add(Dropout(0.15))\n","#model.add(Flatten())\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_55\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_223 (Conv2D)          (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_223 (Activation)  (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_224 (Conv2D)          (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_224 (Activation)  (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_225 (Conv2D)          (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","activation_225 (Activation)  (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_105 (MaxPoolin (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","dropout_267 (Dropout)        (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_226 (Conv2D)          (None, 16, 16, 64)        18496     \n","_________________________________________________________________\n","activation_226 (Activation)  (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_227 (Conv2D)          (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","activation_227 (Activation)  (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_228 (Conv2D)          (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","activation_228 (Activation)  (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_106 (MaxPoolin (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_268 (Dropout)        (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_229 (Conv2D)          (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","activation_229 (Activation)  (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_230 (Conv2D)          (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_230 (Activation)  (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_231 (Conv2D)          (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","activation_231 (Activation)  (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","max_pooling2d_107 (MaxPoolin (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_269 (Dropout)        (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_54 (Flatten)         (None, 2048)              0         \n","_________________________________________________________________\n","dense_220 (Dense)            (None, 501)               1026549   \n","_________________________________________________________________\n","dense_221 (Dense)            (None, 327)               164154    \n","_________________________________________________________________\n","dense_222 (Dense)            (None, 285)               93480     \n","_________________________________________________________________\n","dropout_270 (Dropout)        (None, 285)               0         \n","_________________________________________________________________\n","dense_223 (Dense)            (None, 10)                2860      \n","=================================================================\n","Total params: 1,767,811\n","Trainable params: 1,767,811\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ytW2xo6xXz3a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"status":"ok","timestamp":1589986473985,"user_tz":-60,"elapsed":405189,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"outputId":"6194fd41-0ded-4302-b389-021123872267"},"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n","\n","opt =  RMSprop(lr=0.0001, decay=1e-6)\n","\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","history = model.fit(x_train_recon_phase, y1_train_class,validation_split=0.2, batch_size=32, epochs=50,callbacks=[early_stopping])\n","\n","score = model.evaluate(x_test_recon_phase, y1_test_class, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.9962 - accuracy: 0.2948 - val_loss: 1.7939 - val_accuracy: 0.3773\n","Epoch 2/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.7257 - accuracy: 0.3988 - val_loss: 1.6677 - val_accuracy: 0.4210\n","Epoch 3/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.5993 - accuracy: 0.4479 - val_loss: 1.6096 - val_accuracy: 0.4527\n","Epoch 4/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.5070 - accuracy: 0.4821 - val_loss: 1.6257 - val_accuracy: 0.4456\n","Epoch 5/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.4324 - accuracy: 0.5072 - val_loss: 1.5638 - val_accuracy: 0.4680\n","Epoch 6/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.3585 - accuracy: 0.5342 - val_loss: 1.5726 - val_accuracy: 0.4640\n","Epoch 7/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.2818 - accuracy: 0.5610 - val_loss: 1.5838 - val_accuracy: 0.4629\n","Epoch 8/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.2124 - accuracy: 0.5842 - val_loss: 1.6029 - val_accuracy: 0.4581\n","Epoch 9/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.1325 - accuracy: 0.6107 - val_loss: 1.6518 - val_accuracy: 0.4588\n","Epoch 10/50\n","1250/1250 [==============================] - 40s 32ms/step - loss: 1.0519 - accuracy: 0.6357 - val_loss: 1.7406 - val_accuracy: 0.4476\n","Test loss: 1.728593111038208\n","Test accuracy: 0.44909998774528503\n"],"name":"stdout"}]}]}