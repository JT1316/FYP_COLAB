{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FYP_SHUFFLE.ipynb","provenance":[],"authorship_tag":"ABX9TyOnh4ZZlEdMaZjYvqzUwdRW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GTSP6pqxpe0h","colab_type":"code","outputId":"7a685b15-5db7-4805-e16c-17b23d77e311","executionInfo":{"status":"ok","timestamp":1589281948968,"user_tz":-60,"elapsed":5202,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["import numpy as np\n","np.random.seed(123)\n","from tensorflow.keras.models import Sequential\n","#sequential is a stack of nerual network layers\n","import tensorflow as tf\n","tf.random.set_seed(123)\n","\n","from tensorflow.keras.layers import Dense, Activation\n","#dense is a ully connected network, activation is a non linear function applied to the network.\n","\n","from keras.utils import np_utils\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import mnist\n","(X_train1, y_train1), (X_test1, y_test1) = mnist.load_data()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DQjTkonupy4E","colab_type":"code","colab":{}},"source":["def compute_mag_phase(toBeTransfromed):\n","    dft = np.fft.fft2(toBeTransfromed)\n","    dft_shift = np.fft.fftshift(dft)\n","    mag = np.abs(dft_shift)\n","    ang = np.angle(dft_shift)\n","    return mag, ang\n","\n","def reconstruct(mag,ang):\n","    combined = np.multiply(mag, np.exp(1j*ang))\n","    #combinedReal = np.real(combined)\n","    #combinedImag = np.imag(combined)\n","    fftx = np.fft.ifftshift(combined)\n","    ffty = np.fft.ifft2(fftx)\n","    imgCombined = np.abs(ffty)\n","    return imgCombined\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRO0Z8ahp6cB","colab_type":"code","colab":{}},"source":["def pre_process_shuffle(dataset):\n","  mag = np.zeros(dataset.shape)\n","  phase = np.zeros(dataset.shape)\n","  shuffle = np.zeros(dataset.shape)\n","  phase_shuffle = np.zeros(dataset.shape)\n","  x= 0\n","  for i in range(0,dataset.shape[0]):\n","    mag[i,:,:],phase[i,:,:] = compute_mag_phase(dataset[i])\n","  ind = np.arange(phase.shape[0])\n","  np.random.shuffle(ind)\n","  phase_shuffle  = phase[ind,: , :]\n","  for i in range(0,dataset.shape[0]):\n","    shuffle[i,:,:] = reconstruct(mag[i],phase_shuffle[i])\n","  return shuffle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTnDjtfdq6cS","colab_type":"code","colab":{}},"source":["X_train_shuff= pre_process_shuffle(X_train1)\n","X_test_shuff = pre_process_shuffle(X_test1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckaAI7cEyyEM","colab_type":"code","outputId":"8657e0f4-0e32-4ce9-96eb-46ec3f0f5829","executionInfo":{"status":"ok","timestamp":1586819951136,"user_tz":-60,"elapsed":27604,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["plt.subplot(111)\n","plt.imshow(X_train_shuff[8], cmap='gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f749fd457f0>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"92V4Gslc05ff","colab_type":"code","colab":{}},"source":["X_train_flatten = X_train_shuff.reshape(X_train_shuff.shape[0], X_train_shuff.shape[1] * X_train_shuff.shape[2])\n","X_test_flatten = X_test_shuff.reshape(X_test_shuff.shape[0], X_test_shuff.shape[1] * X_test_shuff.shape[2])\n","\n","X_train_flatten = X_train_flatten.astype('float32')\n","X_test_flatten = X_test_flatten.astype('float32')\n","X_train_flatten /= 255\n","X_test_flatten /= 255\n","Y_train_class = np_utils.to_categorical(y_train1, 10)\n","Y_test_class = np_utils.to_categorical(y_test1, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA39_mYq1JEG","colab_type":"code","colab":{}},"source":["model = Sequential([\n","    Dense(10, input_shape=(784,)),\n","    Activation('softmax'),\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dD54fQYZ1L9j","colab_type":"code","outputId":"939482cf-69f3-413c-9d48-58fb28cebba2","executionInfo":{"status":"ok","timestamp":1586819958599,"user_tz":-60,"elapsed":35046,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"colab":{"base_uri":"https://localhost:8080/","height":239}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 10)                7850      \n","_________________________________________________________________\n","activation (Activation)      (None, 10)                0         \n","=================================================================\n","Total params: 7,850\n","Trainable params: 7,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"579gsYKC1M06","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNrI9ind1SMR","colab_type":"code","outputId":"f253298d-3292-4b53-8f4e-1f5069a5de6e","executionInfo":{"status":"error","timestamp":1586819967659,"user_tz":-60,"elapsed":44092,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["history = model.fit(X_train_flatten, Y_train_class, batch_size=32, epochs=100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1875/1875 [==============================] - 4s 2ms/step - loss: 2.1633 - accuracy: 0.2207\n","Epoch 2/100\n","1875/1875 [==============================] - 4s 2ms/step - loss: 2.0828 - accuracy: 0.2628\n","Epoch 3/100\n"," 228/1875 [==>...........................] - ETA: 3s - loss: 2.0505 - accuracy: 0.2762"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-6f6744bd1b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"lJqBLoQkO_DZ","colab_type":"text"},"source":["\n","very low accuracy when phase is shuffled, only about a third correct so far (no hidden layers though)"]},{"cell_type":"code","metadata":{"id":"HXLq0Iucr8Ac","colab_type":"code","colab":{}},"source":["from keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from keras.utils.np_utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Helper: Early stopping.\n","early_stopper = EarlyStopping(patience=5)\n","\n","def get_mnist():\n","    \"\"\"Retrieve the MNIST dataset and process the data.\"\"\"\n","    # Set defaults.\n","    nb_classes = 10\n","    batch_size = 128\n","    input_shape = (784,)\n","\n","    # Get the data.\n","    x_train = X_train_flatten\n","    x_test = X_test_flatten\n","\n","    # convert class vectors to binary class matrices\n","    y_train = to_categorical(y_train1, nb_classes)\n","    y_test = to_categorical(y_test1, nb_classes)\n","    print('done mnist')\n","    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n","\n","def compile_model(network, nb_classes, input_shape):\n","    \"\"\"Compile a sequential model.\n","    Args:\n","        network (dict): the parameters of the network\n","    Returns:\n","        a compiled network.\n","    \"\"\"\n","    # Get our network parameters.\n","    nb_layers = network['nb_layers']\n","    nb_neurons1 = network['nb_neurons1']\n","    nb_neurons2 = network['nb_neurons2']\n","    nb_neurons3 = network['nb_neurons3']\n","    nb_neurons4 = network['nb_neurons4']\n","    activation = network['activation']\n","    optimizer = network['optimizer']\n","\n","    model = Sequential()\n","\n","    # Add each layer.\n","    for i in range(nb_layers):\n","\n","        # Need input shape for first layer.\n","        if i == 0:\n","            model.add(Dense(nb_neurons1, activation=activation, input_shape=input_shape))\n","        elif i == 1:\n","            model.add(Dense(nb_neurons2, activation=activation))\n","        elif i == 2:\n","            model.add(Dense(nb_neurons3, activation=activation))\n","        elif i == 3:\n","            model.add(Dense(nb_neurons4, activation=activation))\n","\n","        model.add(Dropout(0.2))  # hard-coded dropout\n","\n","    # Output layer.\n","    model.add(Dense(nb_classes, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n","                  metrics=['accuracy'])\n","    print('compiled model')\n","    return model\n","\n","def train_and_score(network, dataset):\n","    \"\"\"Train the model, return test loss.\n","    Args:\n","        network (dict): the parameters of the network\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","    logging.info(\"***train_and_score***\")\n","    if dataset == 'cifar10':\n","        nb_classes, batch_size, input_shape, x_train, \\\n","            x_test, y_train, y_test = get_cifar10()\n","    elif dataset == 'mnist':\n","        logging.info(\"***mnist***\")\n","        nb_classes, batch_size, input_shape, x_train, \\\n","            x_test, y_train, y_test = get_mnist()\n","\n","    model = compile_model(network, nb_classes, input_shape)\n","    logging.info(\"***compiled_model***\")\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=100,  # using early stopping, so no real limit\n","              verbose=0,\n","              validation_split=0.2,\n","              callbacks=[early_stopper])\n","    #validation_split=0.2, epochs=100, batch_size=2000,\n","    #validation_data=(x_test, y_test),\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    logging.info(\"***trainedd***\")\n","    print(score[1])\n","    return score[1]  # 1 is accuracy. 0 is loss."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HraI_d3jNQlh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhTr5ZjdNQu-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxEJroE9wTdh","colab_type":"code","colab":{}},"source":["import random\n","import logging\n","#from train import train_and_score\n","\n","class Network():\n","    \"\"\"Represent a network and let us operate on it.\n","    Currently only works for an MLP.\n","    \"\"\"\n","\n","    def __init__(self, nn_param_choices=None):\n","        \"\"\"Initialize our network.\n","        Args:\n","            nn_param_choices (dict): Parameters for the network, includes:\n","                nb_neurons (list): [64, 128, 256]\n","                nb_layers (list): [1, 2, 3, 4]\n","                activation (list): ['relu', 'elu']\n","                optimizer (list): ['rmsprop', 'adam']\n","        \"\"\"\n","        self.accuracy = 0.\n","        self.nn_param_choices = nn_param_choices\n","        self.network = {}  # (dic): represents MLP network parameters\n","\n","    def create_random(self):\n","        i = True \n","        \"\"\"Create a random network.\"\"\"\n","        for key in self.nn_param_choices:\n","            if key == 'nb_neurons2':\n","              while (True):\n","                logging.info(\"stuck 1\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons1']:\n","                  break\n","            elif key == 'nb_neurons3':\n","              while (True):\n","                logging.info(\"stuck 2\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons2']:\n","                  break\n","            elif key == 'nb_neurons4':\n","              while (True):\n","                logging.info(\"stuck 3\")\n","                self.network[key] = random.choice(self.nn_param_choices[key])\n","                if self.network[key] < self.network['nb_neurons3']:\n","                  break\n","            else:\n","              self.network[key] = random.choice(self.nn_param_choices[key])\n","\n","\n","\n","    def create_set(self, network):\n","        \"\"\"Set network properties.\n","        Args:\n","            network (dict): The network parameters\n","        \"\"\"\n","        self.network = network\n","\n","    def train(self, dataset):\n","        \"\"\"Train the network and record the accuracy.\n","        Args:\n","            dataset (str): Name of dataset to use.\n","        \"\"\"\n","        logging.info(\"***train***\")\n","        if self.accuracy == 0.:\n","            self.accuracy = train_and_score(self.network, dataset)\n","\n","    def print_network(self):\n","        \"\"\"Print out a network.\"\"\"\n","        logging.info(self.network)\n","        logging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqJLLoL_NQyS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2Y5DIPSNQ2b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJdyGbFwxrOV","colab_type":"code","colab":{}},"source":["from functools import reduce\n","from operator import add\n","import random\n","\n","\n","class Optimizer():\n","    \"\"\"Class that implements genetic algorithm for MLP optimization.\"\"\"\n","\n","    def __init__(self, nn_param_choices, retain=0.4,\n","                 random_select=0.1, mutate_chance=0.3):\n","        \"\"\"Create an optimizer.\n","        Args:\n","            nn_param_choices (dict): Possible network paremters\n","            retain (float): Percentage of population to retain after\n","                each generation\n","            random_select (float): Probability of a rejected network\n","                remaining in the population\n","            mutate_chance (float): Probability a network will be\n","                randomly mutated\n","        \"\"\"\n","        self.mutate_chance = mutate_chance\n","        self.random_select = random_select\n","        self.retain = retain\n","        self.nn_param_choices = nn_param_choices\n","\n","    def create_population(self, count):\n","        \"\"\"Create a population of random networks.\n","        Args:\n","            count (int): Number of networks to generate, aka the\n","                size of the population\n","        Returns:\n","            (list): Population of network objects\n","        \"\"\"\n","        pop = []\n","        for _ in range(0, count):\n","            # Create a random network.\n","            network = Network(self.nn_param_choices)\n","            logging.info(\"count\")\n","            network.create_random()\n","\n","            # Add the network to our population.\n","            pop.append(network)\n","\n","        return pop\n","\n","    @staticmethod\n","    def fitness(network):\n","        \"\"\"Return the accuracy, which is our fitness function.\"\"\"\n","        return network.accuracy\n","\n","    def grade(self, pop):\n","        \"\"\"Find average fitness for a population.\n","        Args:\n","            pop (list): The population of networks\n","        Returns:\n","            (float): The average accuracy of the population\n","        \"\"\"\n","        summed = reduce(add, (self.fitness(network) for network in pop))\n","        return summed / float((len(pop)))\n","\n","    def breed(self, mother, father):\n","        \"\"\"Make two children as parts of their parents.\n","        Args:\n","            mother (dict): Network parameters\n","            father (dict): Network parameters\n","        Returns:\n","            (list): Two network objects\n","        \"\"\"\n","        children = []\n","        for _ in range(2):\n","\n","            child = {}\n","\n","            #  need to do if they have equal layers\n","            # Loop through the parameters and pick params for the kid.\n","            for param in self.nn_param_choices:\n","                  if (param == 'nb_neurons2') :\n","                    while (True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons1']:\n","                            logging.info(\"***broke1***\")\n","                            break\n","                  elif param == 'nb_neurons3':\n","                    while ( True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons2']:\n","                            break\n","                            logging.info(\"***broke2***\")\n","                  elif param == 'nb_neurons4':\n","                    while (True):\n","                        child[param] = random.choice([mother.network[param], father.network[param]])\n","                        if child[param] < child['nb_neurons3']:\n","                            break\n","                            logging.info(\"***broke3***\")\n","                  else:\n","                    child[param] = random.choice([mother.network[param], father.network[param]])\n","\n","            # Now create a network object.\n","            network = Network(self.nn_param_choices)\n","            network.create_set(child)\n","\n","            # Randomly mutate some of the children.\n","            if self.mutate_chance > random.random():\n","                network = self.mutate(network)\n","\n","            children.append(network)\n","\n","        return children\n","\n","    def mutate(self, network):\n","        \"\"\"Randomly mutate one part of the network.\n","        Args:\n","            network (dict): The network parameters to mutate\n","        Returns:\n","            (Network): A randomly mutated network object\n","        \"\"\"\n","        # Choose a random key.\n","\n"," \n","        mutation = random.choice(list(self.nn_param_choices.keys()))\n","        \n","        #mutate param within condition\n","        if mutation == 'nb_neurons1':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons2']):\n","                    break\n","        elif mutation == 'nb_neurons2':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons3']) and (network.network[mutation] < network.network['nb_neurons1']) :\n","                    break\n","        elif mutation == 'nb_neurons3':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] > network.network['nb_neurons4'])  and (network.network[mutation] < network.network['nb_neurons2']):\n","                    break\n","        elif mutation == 'nb_neurons4':\n","            while (True):\n","                  network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","                  if (network.network[mutation] < network.network['nb_neurons3']):\n","                    break\n","        else:\n","          # Mutate one of the params.\n","          network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n","        return network\n","\n","    def evolve(self, pop):\n","        \"\"\"Evolve a population of networks.\n","        Args:\n","            pop (list): A list of network parameters\n","        Returns:\n","            (list): The evolved population of networks\n","        \"\"\"\n","        # Get scores for each network.\n","        graded = [(self.fitness(network), network) for network in pop]\n","\n","        # Sort on the scores.\n","        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n","\n","        # Get the number we want to keep for the next gen.\n","        retain_length = int(len(graded)*self.retain)\n","\n","        # The parents are every network we want to keep.\n","        parents = graded[:retain_length]\n","\n","        # For those we aren't keeping, randomly keep some anyway.\n","        for individual in graded[retain_length:]:\n","            if self.random_select > random.random():\n","                parents.append(individual)\n","\n","        # Now find out how many spots we have left to fill.\n","        parents_length = len(parents)\n","        desired_length = len(pop) - parents_length\n","        children = []\n","\n","        # Add children, which are bred from two remaining networks.\n","        while len(children) < desired_length:\n","\n","            # Get a random mom and dad.\n","            print(parents_length-1)\n","            male = random.randint(0, parents_length-1)\n","\n","            female = random.randint(0, parents_length-1)\n","\n","            # Assuming they aren't the same network...\n","            if male != female:\n","                male = parents[male]\n","                female = parents[female]\n","\n","                # Breed them.\n","                babies = self.breed(male, female)\n","\n","                # Add the children one at a time.\n","                for baby in babies:\n","                    # Don't grow larger than desired length.\n","                    if len(children) < desired_length:\n","                        children.append(baby)\n","\n","        parents.extend(children)\n","\n","        return parents"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZN2V5xtNQ5K","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sxUdLprNu_u","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqbzxloSyZVL","colab_type":"code","outputId":"5e3b9a17-4fcb-4d33-9540-b35c0865bc9d","executionInfo":{"status":"ok","timestamp":1586628560813,"user_tz":-60,"elapsed":3293309,"user":{"displayName":"Jamie-Lee Thompson","photoUrl":"","userId":"10099900452975195481"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import logging\n","from tqdm import tqdm\n","\n","# Setup logging.\n","logging.basicConfig(\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    datefmt='%m/%d/%Y %I:%M:%S %p',\n","    level=logging.DEBUG,\n","    filename='log.txt'\n",")\n","\n","def train_networks(networks, dataset):\n","    \"\"\"Train each network.\n","    Args:\n","        networks (list): Current population of networks\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","\n","    pbar = tqdm(total=len(networks))\n","    logging.info(\"***a***\")\n","    for network in networks:\n","        network.train(dataset)\n","        pbar.update(1)\n","        logging.info(\"***b***\")\n","    pbar.close()\n","\n","def get_average_accuracy(networks):\n","    \"\"\"Get the average accuracy for a group of networks.\n","    Args:\n","        networks (list): List of networks\n","    Returns:\n","        float: The average accuracy of a population of networks.\n","    \"\"\"\n","    total_accuracy = 0\n","    for network in networks:\n","        total_accuracy += network.accuracy\n","\n","    return total_accuracy / len(networks)\n","\n","def generate(generations, population, nn_param_choices, dataset):\n","    \"\"\"Generate a network with the genetic algorithm.\n","    Args:\n","        generations (int): Number of times to evole the population\n","        population (int): Number of networks in each generation\n","        nn_param_choices (dict): Parameter choices for networks\n","        dataset (str): Dataset to use for training/evaluating\n","    \"\"\"\n","    optimizer = Optimizer(nn_param_choices)\n","    logging.info(\"***Optimizer***\")\n","    networks = optimizer.create_population(population)\n","\n","    # Evolve the generation.\n","    for i in range(generations):\n","        logging.info(\"***Doing generation %d of %d***\" %\n","                     (i + 1, generations))\n","\n","        # Train and get accuracy for networks.\n","        train_networks(networks, dataset)\n","        logging.info(\"***Trained networks***\")\n","        # Get the average accuracy for this generation.\n","        average_accuracy = get_average_accuracy(networks)\n","\n","        # Print out the average accuracy each generation.\n","        logging.info(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n","        logging.info('-'*80)\n","\n","        # Evolve, except on the last iteration.\n","        if i != generations - 1:\n","            # Do the evolution.\n","            networks = optimizer.evolve(networks)\n","\n","    # Sort our final population.\n","    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n","\n","    # Print out the top 5 networks.\n","    print_networks(networks[:5])\n","\n","def print_networks(networks):\n","    \"\"\"Print a list of networks.\n","    Args:\n","        networks (list): The population of networks\n","    \"\"\"\n","    logging.info('-'*80)\n","    for network in networks:\n","        network.print_network()\n","\n","def main():\n","    \"\"\"Evolve a network.\"\"\"\n","    generations = 7  # Number of times to evole the population.\n","    population = 20  # Number of networks in each generation.\n","    dataset = 'mnist'\n","    print(2)\n","\n","    nn_param_choices = {\n","        #'nb_neurons': [10, 60, 110, 160, 210, 260,310,360,410,460,510],\n","        'nb_neurons1': range(14,780),\n","        'nb_neurons2':  range(13,779),\n","        'nb_neurons3': range(12,778),\n","        'nb_neurons4': range(11,777),\n","        'nb_layers': [1, 2, 3, 4],\n","        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n","        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n","                      'adadelta', 'adamax', 'nadam'],\n","    }\n","    print(3)\n","    logging.info(\"***Evolving %d generations with population %d***\" %\n","                 (generations, population))\n","    print(4)\n","    generate(generations, population, nn_param_choices, dataset)\n","    print('done')\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["2\n","3\n","4\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r  5%|▌         | 1/20 [00:21<06:48, 21.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.2709999978542328\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 10%|█         | 2/20 [01:10<08:57, 29.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5551000237464905\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 15%|█▌        | 3/20 [02:27<12:24, 43.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.46160000562667847\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|██        | 4/20 [02:56<10:32, 39.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5716000199317932\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|██▌       | 5/20 [03:51<11:00, 44.05s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.4325999915599823\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|███       | 6/20 [04:44<10:53, 46.69s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.4966999888420105\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 35%|███▌      | 7/20 [06:00<12:02, 55.55s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.2476000040769577\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|████      | 8/20 [06:22<09:06, 45.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.520799994468689\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 45%|████▌     | 9/20 [06:47<07:11, 39.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5785999894142151\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 10/20 [08:05<08:28, 50.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.3752000033855438\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [08:29<06:26, 42.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5408999919891357\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [09:53<07:22, 55.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.4424000084400177\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [10:12<05:10, 44.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5730000138282776\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [11:24<05:15, 52.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.414900004863739\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 15/20 [12:13<04:18, 51.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5906000137329102\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 16/20 [12:37<02:53, 43.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5870000123977661\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 17/20 [13:56<02:42, 54.13s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5799999833106995\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 18/20 [14:37<01:40, 50.07s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5727999806404114\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 19/20 [14:56<00:40, 40.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5728999972343445\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20/20 [16:18<00:00, 48.94s/it]\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0.2766000032424927\n","9\n","9\n","9\n","9\n","9\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [01:20<01:05,  7.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5828999876976013\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [01:38<01:24, 10.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5920000076293945\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [02:13<02:05, 17.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.570900022983551\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [02:48<02:18, 23.07s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5676000118255615\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 15/20 [03:28<02:20, 28.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.57669997215271\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 16/20 [04:08<02:06, 31.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5770999789237976\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 17/20 [04:24<01:21, 27.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5713000297546387\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 18/20 [04:47<00:51, 25.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5713000297546387\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 19/20 [05:17<00:27, 27.13s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5738999843597412\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20/20 [05:41<00:00, 17.07s/it]\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0.583899974822998\n","7\n","7\n","7\n","7\n","7\n","7\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 45%|████▌     | 9/20 [00:45<00:56,  5.09s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5623999834060669\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 10/20 [01:12<01:54, 11.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5906999707221985\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [01:34<02:11, 14.61s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5723000168800354\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [02:01<02:28, 18.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5885000228881836\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [02:32<02:35, 22.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5906000137329102\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [03:06<02:34, 25.73s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5914999842643738\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 15/20 [03:30<02:06, 25.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5813999772071838\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 16/20 [04:13<02:01, 30.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5794000029563904\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 17/20 [05:32<02:15, 45.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5794000029563904\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 18/20 [06:13<01:27, 43.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.578499972820282\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 19/20 [06:39<00:38, 38.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5755000114440918\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20/20 [06:54<00:00, 20.73s/it]\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0.5770000219345093\n","8\n","8\n","8\n","8\n","8\n","8\n","8\n","8\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 10/20 [00:21<00:21,  2.18s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5759999752044678\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [01:12<02:30, 16.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5903000235557556\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [01:43<02:48, 21.07s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.567300021648407\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [02:10<02:38, 22.68s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5884000062942505\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [02:35<02:20, 23.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5353000164031982\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 15/20 [03:11<02:15, 27.10s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5860000252723694\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 16/20 [03:46<01:58, 29.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5848000049591064\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 17/20 [04:33<01:44, 34.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.54339998960495\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 18/20 [04:52<00:59, 29.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5796999931335449\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 19/20 [05:36<00:34, 34.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5986999869346619\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 20/20 [06:04<00:00, 18.25s/it]\n","  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["0.5867000222206116\n","9\n","9\n","9\n","9\n","9\n","9\n","9\n","9\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [00:33<00:27,  3.04s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5950000286102295\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [01:06<01:37, 12.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.597000002861023\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [01:36<02:01, 17.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.5720000267028809\n","done mnist\n","compiled model\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [02:27<02:44, 27.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.6000000238418579\n","done mnist\n","compiled model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IkxVf5284S3I","colab_type":"text"},"source":["Around 60% - p good considering."]}]}